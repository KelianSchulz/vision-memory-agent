# ğŸ§  Vision Memory Agent

A self-reflecting AI agent that selects and remembers images based on semantic similarity to a goal â€” and dynamically adjusts that goal using GPT when it fails.

---

## ğŸš€ What it does

- Uses OpenAI's CLIP to compare images from the CIFAR-10 dataset with a goal phrase (e.g. `"a cat in a red car"`)
- If the agent finds **too few relevant images**, it asks GPT for **better goal alternatives**
- Repeats the search with the new goal until it succeeds or exhausts its attempts
- Stores the **final goal** and **relevant image indices + scores** in `agent_memory.json`

---

## ğŸ¤– How it works

1. Embed the goal phrase and CIFAR-10 images using CLIP
2. Compute cosine similarity for each image
3. If less than 5 matches are found:
   - Ask GPT: *"Suggest better goals for CIFAR-10"*
   - Use GPT's first suggestion as the new goal
   - Try again (up to 5 times)

---

## ğŸ§ª Example Output

```
ğŸ¯ Attempt 1/5 â€“ Searching for goal: 'a cat in a red car'
âš ï¸ Too few matches â€“ asking GPT...

ğŸ” GPT suggestions:
â†’ "a tuxedo cat on a red sofa"
â†’ "a black dog playing on grass"
â†’ "a bird flying over a lake"

ğŸ¯ Attempt 2/5 â€“ Searching for goal: 'a tuxedo cat on a red sofa'
âœ… Found 6 relevant images.
```

---

## ğŸ“ Files

- `vision_agent.py` â€“ main agent loop
- `embedding.py` â€“ helper functions for CLIP
- `gpt_helpers.py` â€“ GPT-powered goal suggestions
- `visualize_memory.py` â€“ visualize results
- `agent_memory.json` â€“ stores results and final goal

---

## ğŸ§  Why it's interesting

This project explores **semantic self-correction** in agents:
- Can a visual agent notice its own failure?
- Can it adjust goals using language?
- Can it learn to "try better"?

---

## ğŸ“„ See also

ğŸ‘‰ [`agent_architecture.md`](agent_architecture.md) â€“ for full explanation of system design & reasoning loop.


## âœï¸ Author

Built by Kelian Schulz â€“ as part of a deeper exploration into  
interpretable, goal-driven agents for applied AI research.
