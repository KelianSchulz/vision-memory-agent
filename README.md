# ğŸ§  Vision Memory Agent

A self-reflecting AI agent that selects and remembers images based on semantic similarity to a goal â€” and dynamically adjusts that goal using GPT when it fails.

---

## ğŸš€ What it does

- Uses OpenAI's CLIP to compare images from the CIFAR-10 dataset with a goal phrase (e.g. `"a cat in a red car"`)
- If the agent finds **too few relevant images**, it asks GPT for **1 refined alternative**
- Repeats the search with the new goal until it succeeds or hits 5 attempts
- Stores the **final goal** and **relevant image indices + scores** in `agent_memory.json`

---

## ğŸ¤– How it works

1. Embed the goal phrase and CIFAR-10 images using CLIP
2. Compute cosine similarity for each image
3. If not enough matches are found:
   - Ask GPT: *"Suggest 1 short alternative close to original, avoiding tested ones"*
   - Try again with the new suggestion

---

## ğŸ§ª Example Output

```
ğŸ¯ Attempt 1/5 â€“ Searching for goal: 'a fire truck in the rain'
âš ï¸ Too few matches â€“ asking GPT...

ğŸ” GPT suggestion:
â†’ rainy fire engine

ğŸ¯ Attempt 2/5 â€“ Searching for goal: 'rainy fire engine'
âœ… Found 11 relevant images.
```

---

## ğŸ“ Files

- `vision_agent.py` â€“ main agent loop
- `embedding.py` â€“ helper functions for CLIP
- `gpt_helpers.py` â€“ GPT-powered goal suggestions
- `visualize_memory.py` â€“ visualize results
- `agent_memory.json` â€“ stores successful goal and matches
- `goal_trace.json` â€“ logs every attempt with hit stats

---

## ğŸ§  Why it's interesting

This project explores **semantic self-correction** in agents:
- Can a visual agent recognize its own failure?
- Can it reformulate its goal using language?
- Can it learn to improve search through meaning, not just code?

---

## ğŸ“„ See also

ğŸ‘‰ [`agent_architecture.md`](agent_architecture.md) â€“ for full explanation of the reflection loop and system components.

---

## âœï¸ Author

Built by **Kelian Schulz** â€“ as part of an independent research journey into  
interpretable, reflective, and goal-driven AI agents.