# ðŸ§  Reflection Agent â€“ Forschungstagebuch

## Projektidee

Ein visueller Agent, der erkennt, wenn sein Ziel fehlerhaft ist,  
und sich sprachgestÃ¼tzt ein neues Ziel vorschlagen lÃ¤sst.  
Er verÃ¤ndert sein Verhalten in Schleifen, bis er erfolgreich ist.

---

## Aktueller Zustand

- Ziel: visuell relevante Bilder zu einem gegebenen Zieltext finden
- Mechanismus:
  - CLIP zur Bewertung der Relevanz
  - GPT zur Zielreflexion bei Misserfolg
  - SelbststÃ¤ndiges Weiterlaufen mit neuem Ziel
- Erfolgskriterium: mindestens 5 relevante Treffer bei Score > 0.29

---

## Erste Forschungsfrage (Entwurf)

> Wie erkennt ein Agent, dass sein Ziel fehlerhaft ist â€“  
und wie effektiv ist sprachbasierte Zielreflexion im Vergleich zu alternativen Mechanismen?

---

## Was funktioniert bisher

- Agent erkennt Zielversagen (`len(agent_memory) < threshold`)
- GPT generiert neue ZielvorschlÃ¤ge
- Agent Ã¼bernimmt erstes GPT-Ziel automatisch
- Zielpfade sind nachvollziehbar (werden geloggt)
- Bilder werden korrekt gespeichert und visualisiert

---

## Offene Fragen

- Wie stark driften ZielvorschlÃ¤ge semantisch vom Ausgangspunkt ab?
- Wie relevant sind die VorschlÃ¤ge im VerhÃ¤ltnis zum Dataset?
- Wie kÃ¶nnte der Agent aus frÃ¼heren Erfolgen lernen?
- Braucht es eine semantische Metrik zwischen Zielen?

---

## NÃ¤chste Schritte

- Zielverlauf automatisch loggen (mit Scores, GPT-VorschlÃ¤gen, Trefferquote)
- Vergleich: GPT vs. statische Alternativen vs. CLIP-basierte Reflektion
- Visualisierung als Entscheidungsgraph (Ziel â†’ GPT â†’ Ziel â†’ Erfolg)
- Paper-Skizze anlegen?
